<CRANTaskView>

<name>Cluster</name>
<topic>Cluster Analysis &amp; Finite Mixture Models</topic>
<maintainer email="Bettina.Gruen@jku.at">Friedrich Leisch and Bettina Gruen</maintainer>
<version>2013-12-12</version>
  
<info> This CRAN Task View contains a list of packages that can be
used for finding groups in data and modelling unobserved
cross-sectional heterogeneity. Many packages provide functionality for
more than one of the topics listed below, the section headings are
mainly meant as quick starting points rather than an ultimate
categorization. Except for packages stats and cluster (which ship with
base R and hence are part of every R installation), each package is
listed only once.
<p>Most of the packages listed in this CRAN Task View, but not all are
distributed under the GPL. Please have a look at the DESCRIPTION file
of each package to check under which license it is distributed.</p>

<p><strong>Hierarchical Clustering:</strong></p>
<ul>
  <li>
  Functions <code>hclust()</code> from package stats and
  <code>agnes()</code> from <pkg>cluster</pkg> are the primary
  functions for agglomerative hierarchical clustering, function
  <code>diana()</code> can be used for divisive hierarchical
  clustering. Faster alternatives to <code>hclust()</code> are
  provided by the packages <pkg>fastcluster</pkg> and
  <pkg>flashClust</pkg>.</li>
  <li>Function <code>dendrogram()</code> from stats and associated
  methods can be used for improved visualization for cluster
  dendrograms.</li>
  <li>Package <pkg>dynamicTreeCut</pkg> contains methods for detection
  of clusters in hierarchical clustering dendrograms.</li>
  <li><pkg>hybridHclust</pkg> implements hybrid hierarchical
  clustering via mutual clusters.</li>
  <li>Package <pkg>isopam</pkg> uses an algorithm which is based on
  the classification of ordination scores from isometric feature
  mapping. The classification is performed either as a hierarchical,
  divisive method or as non-hierarchical partitioning.</li>
  <li>The package <pkg>protoclust</pkg> implements a form of
  hierarchical clustering that associates a prototypical element with
  each interior node of the dendrogram.  Using the package's
  <code>plot()</code> function, one can produce dendrograms that are
  prototype-labeled and are therefore easier to interpret.</li>
  <li><pkg>pvclust</pkg> is a package for assessing the uncertainty in
  hierarchical cluster analysis. It provides approximately
  unbiased p-values as well as bootstrap p-values.</li>
  <li>Package <pkg>sparcl</pkg> provides clustering for a set of
  <i>n</i> observations when <i>p</i> variables are available, where
  <i>p</i> &gt;&gt; <i>n</i>. It adaptively chooses a set of variables
  to use in clustering the observations. Sparse K-means clustering and
  sparse hierarchical clustering are implemented.</li>  
</ul>
  
<p><strong>Partitioning Clustering:</strong></p>
<ul>
  <li>Function <code>kmeans()</code> from package stats provides
  several algorithms for computing partitions with respect to
  Euclidean distance.</li>
  <li>Function <code>pam()</code> from package <pkg>cluster</pkg> implements
  partitioning around medoids and can work with arbitrary
  distances. Function <code>clara()</code> is a
  wrapper to <code>pam()</code> for larger data sets. Silhouette plots
  and spanning ellipses can be used for visualization.
  </li>
  <li>Package <pkg>apcluster</pkg> implements Frey's and Dueck's
  Affinity Propagation clustering. The algorithms in the package are analogous
  to the Matlab code published by Frey and Dueck.</li>
  <li>Package <pkg>bayesclust</pkg> allows to test and search for
  clusters in a hierarchical Bayes model.</li>
  <li>Package <pkg>clusterSim</pkg> allows to search for the optimal
  clustering procedure for a given dataset.</li>
  <li>Package <pkg>flexclust</pkg> provides k-centroid cluster
  algorithms for arbitrary distance measures, hard competitive
  learning, neural gas and QT clustering. Neighborhood graphs and
  image plots of partitions are available for visualization. Some of
  this functionality is also provided by package <pkg>cclust</pkg>.
  </li>
  <li>Package <pkg>kernlab</pkg> provides a weighted kernel version of
  the k-means algorithm by <code>kkmeans</code> and spectral
  clustering by <code>specc</code>.</li>
  <li>Packages <pkg>kml</pkg> and <pkg>kml3d</pkg> provide k-means
  clustering specifically for longitudinal (joint) data.</li>
  <li>Package <pkg>skmeans</pkg> allows spherical k-Means Clustering,
   i.e. k-means clustering with cosine similarity. It features several
   methods, including a genetic and a simple fixed-point algorithm and
   an interface to the CLUTO vcluster program for clustering
   high-dimensional datasets.</li>
  <li>Package <pkg>trimcluster</pkg> provides trimmed k-means
  clustering. Package <pkg>tclust</pkg> also allows for trimmed
  k-means clustering. In addition using this package other covariance
  structures can also be specified for the clusters.</li>
</ul>
<p><strong>Model-Based Clustering:</strong></p>
<ul><li>ML estimation:
<ul>
  <li>For semi- or partially supervised problems, where for a part of
  the observations labels are given with certainty or with some
  probability, package <pkg>bgmm</pkg> provides belief-based and
  soft-label mixture modeling for mixtures of Gaussians with the EM
  algorithm.</li> 
  <li><pkg>EMCluster</pkg> provides EM algorithms and several
  efficient initialization methods for model-based clustering of
  finite mixture Gaussian distribution with unstructured dispersion in
  unsupervised as well as semi-supervised learning situation.</li>
  <li>Package <pkg>FisherEM</pkg> is a subspace clustering method
  which allows for efficient unsupervised classification of
  high-dimensional data. It is based on the Gaussian mixture model and
  on the idea that the data lives in a common and low dimensional
  subspace. An EM-like algorithm estimates both the discriminative
  subspace and the parameters of the mixture model.</li>
  <li>Package <pkg>HDclassif</pkg> provides function <code>hddc</code>
  to fit Gaussian mixture model to high-dimensional data where it is
  assumed that the data lives in a lower dimension than the original
  space.</li>
  <li>Package <pkg>HMMmix</pkg> allows to fit mixtures of Gaussians
  with a hidden Markov model for the latent component memberships of
  the clusters which might be derived by combining components of the
  mixture.</li>
  <li>Package <pkg>teigen</pkg> allows to fit multivariate
  t-distribution mixture models (with eigen-decomposed covariance
  structure) from a clustering or classification point of
  view. Package <pkg>longclust</pkg> allows to fit these models as
  well as Gaussian mixture models to longitudinal data.</li>
  <li>Package <pkg>mclust</pkg> fits mixtures of Gaussians using the
  EM algorithm. It allows fine control of volume and shape of
  covariance matrices and agglomerative hierarchical clustering based
  on maximum likelihood. It provides comprehensive strategies using
  hierarchical clustering, EM and the Bayesian Information Criterion
  (BIC) for clustering, density estimation, and discriminant
  analysis. Package <pkg>Rmixmod</pkg> provides tools for fitting
  mixture models of multivariate Gaussian or multinomial components to
  a given data set with either a clustering, a density estimation or a
  discriminant analysis point of view. <pkg>mclust</pkg> provides only
  10 of the 14 possible variance-covariance structures based on the
  eigenvalue decomposition. All 14 variants are provided by packages
  <pkg>mixture</pkg> and <pkg>Rmixmod</pkg>.</li>
  <li>Package <pkg>MetabolAnalyze</pkg> fits mixtures of probabilistic
  principal component analysis with the EM algorithm.</li>
  <li>For grouped conditional data package <pkg>mixdist</pkg> can be
  used.</li>
  <li>Fitting finite mixtures of uni- and multivariate scale mixtures
  of skew-normal distributions with the EM algorithm is provided by
  package <pkg>mixsmsn</pkg>.</li>
  <li>Package <pkg>movMF</pkg> fits finite mixtures of von
  Mises-Fisher distributions with the EM algorithm.</li>
  <li>Package <pkg>MFDA</pkg> implements model-based functional data
  analysis.</li>
  <li>Package <pkg>GLDEX</pkg> fits mixtures of generalized lambda
  distributions and for grouped conditional data package
  <pkg>mixdist</pkg> can be used.</li>
  <li><pkg>mritc</pkg> provides tools for classification using normal
  mixture models and (higher resolution) hidden Markov normal mixture
  models fitted by various methods.</li>
  <li>Parsimonious Gaussian mixture models allow to fit mixtures of
  factor analyzers with a constraints on the components of the factor
  models. Functionality to fit these models is provided in package
  <pkg>pgmm</pkg>.
  </li>
  <li><pkg>prabclus</pkg> clusters a presence-absence matrix
  object by calculating an MDS 
  from the distances, and applying maximum likelihood Gaussian
  mixtures clustering to the MDS
  points.</li>
  <li>Package <pkg>psychomix</pkg> estimates mixtures of the
  dichotomous Rasch model (via conditional ML) and the Bradley-Terry
  model. Package <pkg>mixRasch</pkg> estimates mixture Rasch models,
  including the dichotomous Rasch model, the rating scale model, and
  the partial credit model with joint maximum likelihood estimation.
  </li>
  <li>Package <pkg>pmclust</pkg> allows to use unsupervised
  model-based clustering for high dimensional (ultra) large data. The
  package uses pbdMPI to perform a parallel version of the EM
  algorithm for mixtures of Gaussians.</li>
</ul></li>
<li>Bayesian estimation:
<ul>
  <li>Bayesian estimation of finite mixtures of multivariate Gaussians
  is possible using package <pkg>bayesm</pkg>. The package provides
  functionality for sampling from such a mixture as well as estimating
  the model using Gibbs sampling. Additional functionality for
  analyzing the MCMC chains is available for averaging
  the moments over MCMC draws, for determining the marginal densities,
  for clustering observations and for plotting the uni- and bivariate
  marginal densities.</li>
  <li>Package <pkg>bayesMCClust</pkg> provides various Markov Chain
  Monte Carlo samplers for model-based clustering of discrete-valued
  time series obtained by observing a categorical variable with
  several states using a Bayesian approach.</li>
  <li>Package <pkg>bayesmix</pkg> provides Bayesian estimation using
  JAGS.</li>
  <li>Package <pkg>bclust</pkg> allows Bayesian clustering using a
  spike-and-slab hierarchical model and is suitable for clustering
  high-dimensional data.</li>
  <li>Package <pkg>Bmix</pkg> provides Bayesian Sampling for
  stick-breaking mixtures.</li>
  <li>Package <pkg>dpmixsim</pkg> fits Dirichlet process mixture
  models using conjugate models with normal structure. Package
  <pkg>profdpm</pkg> determines the maximum posterior estimate for
  product partition models where the Dirichlet process mixture is a
  specific case in the class.</li>
  <li>Package <pkg>mixAK</pkg> contains a mixture of statistical
  methods including the MCMC methods to analyze normal mixtures with
  possibly censored data.  </li>
  <li>Package <pkg>GSM</pkg> fits mixtures of gamma distributions.</li> 
  <li>Package <pkg>mcclust</pkg> implements methods for processing a
  sample of (hard) clusterings, e.g. the MCMC output of a Bayesian
  clustering model. Among them are methods that find a single best
  clustering to represent the sample, which are based on the posterior
  similarity matrix or a relabelling algorithm.</li>
  <li>Package <pkg>rjags</pkg> provides an interface to the JAGS
  MCMC library which includes a module for mixture modelling.</li>
</ul></li>
<li>Other estimation methods:
<ul>
  <li>Package <pkg>pendensity</pkg> estimates densities with a penalized
  mixture approach.</li>
  <li>Robust estimation using Weighted Likelihood can be done with
  package <pkg>wle</pkg>.</li>
</ul>
</li>
</ul>
<p><strong>Other Cluster Algorithms:</strong></p>
<ul>
  <li>Package <pkg>amap</pkg> provides alternative implementations
  of k-means and agglomerative hierarchical clustering.</li>
  <li>Package <pkg>biclust</pkg> provides several algorithms to find
  biclusters in two-dimensional data.</li>
  <li>Package <pkg>cba</pkg> implements clustering techniques for
  business analytics like "rock" and "proximus".</li>
  <li>Package <pkg>CHsharp</pkg> clusters 3-dimensional data into
  their local modes based on a convergent form of Choi and Hall's
  (1999) data sharpening method.</li>
  <li>Package <pkg>clue</pkg> implements ensemble methods for both
  hierarchical and partitioning cluster methods.</li>
  <li>Package <pkg>CoClust</pkg> implements a cluster algorithm that
  is based on copula functions and therefore allows to group
  observations according to the multivariate dependence structure of
  the generating process without any assumptions on the margins.</li>
  <li>Fuzzy clustering and bagged clustering are available in
  package <pkg>e1071</pkg>.</li>
  <li>Package <pkg>compHclust</pkg> provides complimentary
  hierarchical clustering which was especially designed for microarray
  data to uncover structures present in the data that arise from
  'weak' genes.</li>
  <li>Package <pkg>FactoClass</pkg> performs a combination of
  factorial methods and cluster analysis.</li>
  <li>The <bioc>hopach</bioc> algorithm is a hybrid between
  hierarchical methods and PAM and builds a tree by
  recursively  partitioning a data set.</li>
  <li>For graphs and networks model-based clustering approaches are
  implemented in packages <pkg>latentnet</pkg> and <pkg>mixer</pkg>.</li>
  <li>Package <pkg>nnclust</pkg> allows fast clustering of large data sets
  by constructing a minimum spanning tree for each cluster. For each
  cluster the procedure is stopped when the nearest-neighbour distance
  rises above a specified threshold. A set of clusters and a
  set of "outliers" not in any cluster is returned. The algorithm works best for 
  well-separated clusters in up to 8 dimensions, and sample sizes up
  to hundreds of thousands.</li>
  <li>Package <pkg>optpart</pkg> contains a set of algorithms for
  creating partitions and coverings of objects largely based on
  operations on similarity relations (or matrices).</li>
  <li>Package <pkg>pdfCluster</pkg> provides tools to perform cluster
  analysis via kernel density estimation. Clusters are associated to
  the maximally connected components with estimated density above a
  threshold. In addition a tree structure associated with the
  connected components is obtained.</li>
  <li>Package <pkg>randomLCA</pkg> provides the fitting of latent
  class models which optionally also include a random effect.  Package
  <pkg>poLCA</pkg> allows for polytomous variable latent class
  analysis and regression. <pkg>BayesLCA</pkg> allows to fit Bayesian
  LCA models employing the EM algorithm, Gibbs sampling or variational
  Bayes methods.</li>
  <li>Package <pkg>RPMM</pkg> fits recursively partitioned mixture
  models for Beta and Gaussian Mixtures. This is a model-based
  clustering algorithm that returns a hierarchy of classes, similar to
  hierarchical clustering, but also similar to finite mixture
  models.</li>
  <li>Self-organizing maps are available in package
  <pkg>som</pkg>.</li>
  <li>Several packages provide cluster algorithms which have been
  developped for bioinformatics applications. These packages include
  <pkg>FunCluster</pkg> for profiling microarray expression data
  and <pkg>ORIClust</pkg>
  for order-restricted information-based clustering.</li>
</ul>
  
<p><strong>Cluster-wise Regression:</strong></p>
<ul>
  <li>Package <pkg>flexmix</pkg> implements an user-extensible
  framework for EM-estimation of mixtures of regression models,
  including mixtures of (generalized) linear models.</li>
  <li>Package <pkg>fpc</pkg> provides fixed-point methods both for
  model-based clustering and linear regression. A collection of
  asymmetric projection methods can be used to plot various
  aspects of a clustering.</li>
  <li>Multigroup mixtures of latent Markov models on mixed categorical
  and continuous data (including time series) can be fitted using
  <pkg>depmix</pkg> or <pkg>depmixS4</pkg>. The parameters are
  optimized using a general purpose optimization routine given linear
  and nonlinear constraints on the parameters.</li>
  <li>Package <pkg>mixreg</pkg> fits mixtures of one-variable
  regressions and provides the bootstrap test for the number of
  components.
  </li>
  <li>Package <pkg>lcmm</pkg> fits a latent class linear mixed model
  which is also known as growth mixture model or heterogeneous linear
  mixed model using a maximum likelihood method.</li>
  <li><pkg>mixtools</pkg> provides fitting with the EM algorithm for
  parametric and non-parametric (multivariate) mixtures. Parametric
  mixtures include mixtures of multinomials, multivariate normals,
  normals with repeated measures, Poisson regressions and Gaussian
  regressions (with random effects). Non-parametric mixtures include
  the univariate semi-parametric case where symmetry is imposed for
  identifiability and multivariate non-parametric mixtures with
  conditional independent assumption. In addition fitting mixtures of
  Gaussian regressions with the Metropolis-Hastings algorithm is
  available.</li>
  <li><pkg>mixPHM</pkg> fits mixtures of proportional hazard models
  with the EM algorithm.</li> <li>Package <pkg>gamlss.mx</pkg> fits
  finite mixtures of of gamlss family distributions.</li> </ul>

<p><strong>Additional Functionality:</strong></p>
<ul>
  <li>Mixtures of univariate normal distributions can be printed
  and plotted using package <pkg>nor1mix</pkg>.</li>
  <li>Package <pkg>gcExplorer</pkg> allows
  to visualise the results of clustering algorithms.</li>
  <li>Package <pkg>clusterGeneration</pkg> contains functions for
  generating random clusters and random covariance/correlation
  matrices, calculating a separation index (data and population
  version) for pairs of clusters or cluster distributions, and 1-D and
  2-D projection plots to visualize clusters.
  Alternatively <pkg>MixSim</pkg> generates a finite mixture model
  with Gaussian components for prespecified levels of maximum and/or
  average overlaps. This model can be used to simulate data for
  studying the performance of cluster algorithms.</li>
  <li>For cluster validation package <pkg>clusterRepro</pkg> tests the
  reproducibility of a cluster. Package <pkg>clv</pkg> contains
  popular internal and external cluster validation methods ready to
  use for most of the outputs produced by functions from package
  <pkg>cluster</pkg> and <pkg>clValid</pkg> calculates several
  stability measures.</li>
  <li>Package <pkg>clustvarsel</pkg> provides variable selection for
  model-based clustering.</li>
  <li>Functionality to compare the similarity between two cluster
  solutions is provided by <code>cluster.stats()</code> in package
  <pkg>fpc</pkg>.</li>
  <li>The stability of k-centroid clustering solutions fitted using
  functions from package <pkg>flexclust</pkg> can also be validated
  via <code>bootFlexclust()</code> using bootstrap methods.</li>
  <li>Package <pkg>MOCCA</pkg> provides methods to analyze cluster
  alternatives based on multi-objective optimization of cluster
  validation indices.</li>
  <li>Package <pkg>SDisc</pkg> provides an integrated methodology for
  the identification of homogeneous profiles in a data distribution by
  including methods for data treatment and pre-processing, repeated
  cluster analysis, model selection, model reliability and
  reproducibility assessment, profiles characterization and validation
  by visual and table summaries.</li>
  <li>Package <pkg>sigclust</pkg> provides a statistical method for
  testing the significance of clustering results.</li>
</ul>
  </info>

<packagelist>
<pkg>amap</pkg>
<pkg>apcluster</pkg>
<pkg>bayesclust</pkg>
<pkg>BayesLCA</pkg>
<pkg>bayesm</pkg>
<pkg>bayesMCClust</pkg>
<pkg>bayesmix</pkg>
<pkg>bgmm</pkg>
<pkg>bclust</pkg>
<pkg>biclust</pkg>
<pkg>Bmix</pkg>
<pkg>cba</pkg>
<pkg>cclust</pkg>
<pkg>CHsharp</pkg>
<pkg>clue</pkg>
<pkg priority="core">cluster</pkg>
<pkg>clusterGeneration</pkg>
<pkg>clusterRepro</pkg>
<pkg>clusterSim</pkg>
<pkg>clustvarsel</pkg>
<pkg>clv</pkg>
<pkg>clValid</pkg>
<pkg>CoClust</pkg>
<pkg>compHclust</pkg>
<pkg>depmix</pkg>
<pkg>depmixS4</pkg>
<pkg>dpmixsim</pkg>
<pkg>dynamicTreeCut</pkg>
<pkg>e1071</pkg>
<pkg>EMCluster</pkg>
<pkg>FactoClass</pkg>
<pkg>flashClust</pkg>
<pkg>fastcluster</pkg>
<pkg>FisherEM</pkg>
<pkg priority="core">flexclust</pkg>
<pkg priority="core">flexmix</pkg>
<pkg>fpc</pkg>
<pkg>FunCluster</pkg>
<pkg>gamlss.mx</pkg>
<pkg>gcExplorer</pkg>
<pkg>GLDEX</pkg>
<pkg>GSM</pkg>
<pkg>HDclassif</pkg>
<pkg>HMMmix</pkg>
<pkg>hybridHclust</pkg>
<pkg>isopam</pkg>
<pkg>kernlab</pkg>
<pkg>kml</pkg>
<pkg>kml3d</pkg>
<pkg>latentnet</pkg>
<pkg>lcmm</pkg>
<pkg>longclust</pkg>
<pkg>mcclust</pkg>
<pkg priority="core">mclust</pkg>
<pkg>MetabolAnalyze</pkg>
<pkg>MFDA</pkg>
<pkg>mixsmsn</pkg>
<pkg>mixAK</pkg>
<pkg>mixdist</pkg>
<pkg>mixer</pkg>
<pkg>mixPHM</pkg>
<pkg>mixRasch</pkg>
<pkg>mixreg</pkg>
<pkg>MixSim</pkg>
<pkg>mixtools</pkg>
<pkg>mixture</pkg>
<pkg>MOCCA</pkg>
<pkg>movMF</pkg>
<pkg>mritc</pkg>
<pkg>nnclust</pkg>
<pkg>nor1mix</pkg>
<pkg>optpart</pkg>
<pkg>ORIClust</pkg>
<pkg>pdfCluster</pkg>
<pkg>pendensity</pkg>
<pkg>pgmm</pkg>
<pkg>pmclust</pkg>
<pkg>poLCA</pkg>
<pkg>prabclus</pkg>
<pkg>profdpm</pkg>
<pkg>protoclust</pkg>
<pkg>psychomix</pkg>
<pkg>pvclust</pkg>
<pkg>randomLCA</pkg>
<pkg>rjags</pkg>
<pkg priority="core">Rmixmod</pkg>
<pkg>Rmpi</pkg>
<pkg>RPMM</pkg>
<pkg>SDisc</pkg>
<pkg>sigclust</pkg>
<pkg>skmeans</pkg>
<pkg>som</pkg>
<pkg>sparcl</pkg>
<pkg>tclust</pkg>
<pkg>teigen</pkg>
<pkg>trimcluster</pkg>
<pkg>wle</pkg>
</packagelist>

<links>
<view>MachineLearning</view>
<bioc>hopach</bioc>
</links>

</CRANTaskView>
