<CRANTaskView>

<name>Cluster</name>
<topic>Cluster Analysis &amp; Finite Mixture Models</topic>
<maintainer email="Bettina.Gruen@jku.at">Friedrich Leisch and Bettina Gruen</maintainer>
<version>2018-07-21</version>
  
<info> <p>This CRAN Task View contains a list of packages that can be
used for finding groups in data and modeling unobserved
cross-sectional heterogeneity. Many packages provide functionality for
more than one of the topics listed below, the section headings are
mainly meant as quick starting points rather than an ultimate
categorization. Except for packages stats and cluster (which ship with
base R and hence are part of every R installation), each package is
listed only once.</p>
<p>Most of the packages listed in this CRAN Task View, but not all are
distributed under the GPL. Please have a look at the DESCRIPTION file
of each package to check under which license it is distributed.</p>

<p><strong>Hierarchical Clustering:</strong></p>
<ul>
  <li>
  Functions <code>hclust()</code> from package stats and
  <code>agnes()</code> from <pkg>cluster</pkg> are the primary
  functions for agglomerative hierarchical clustering, function
  <code>diana()</code> can be used for divisive hierarchical
  clustering. Faster alternatives to <code>hclust()</code> are
  provided by the packages <pkg>fastcluster</pkg> and
  <pkg>flashClust</pkg>.</li>
  <li>Function <code>dendrogram()</code> from stats and associated
  methods can be used for improved visualization for cluster
  dendrograms.</li>
  <li>The <pkg>dendextend</pkg> package provides functions for easy
  visualization (coloring labels and branches, etc.), manipulation
  (rotating, pruning, etc.) and comparison of dendrograms (tangelgrams
  with heuristics for optimal branch rotations, and tree correlation
  measures with bootstrap and permutation tests for
  significance).</li>
  <li>Package <pkg>dynamicTreeCut</pkg> contains methods for detection
  of clusters in hierarchical clustering dendrograms.</li>
  <li>Package <pkg>genie</pkg> implements a fast hierarchical
  clustering algorithm with a linkage criterion which is a variant of
  the single linkage method combining it with the Gini inequality
  measure to robustify the linkage method while retaining
  computational efficiency to allow for the use of larger data
  sets.</li>
  <li><pkg>hybridHclust</pkg> implements hybrid hierarchical
  clustering via mutual clusters.</li>
  <li>Package <pkg>idendr0</pkg> allows to interactively explore
  hierarchical clustering dendrograms and the clustered data. The data
  can be visualized (and interacted with) in a built-in heat map, but
  also in GGobi dynamic interactive graphics (provided by
  rggobi), or base R plots.</li>
  <li>Package <pkg>isopam</pkg> uses an algorithm which is based on
  the classification of ordination scores from isometric feature
  mapping. The classification is performed either as a hierarchical,
  divisive method or as non-hierarchical partitioning.</li>
  <li>The package <pkg>protoclust</pkg> implements a form of
  hierarchical clustering that associates a prototypical element with
  each interior node of the dendrogram.  Using the package's
  <code>plot()</code> function, one can produce dendrograms that are
  prototype-labeled and are therefore easier to interpret.</li>
  <li><pkg>pvclust</pkg> is a package for assessing the uncertainty in
  hierarchical cluster analysis. It provides approximately
  unbiased p-values as well as bootstrap p-values.</li>
</ul>
  
<p><strong>Partitioning Clustering:</strong></p>
<ul>
  <li>Function <code>kmeans()</code> from package stats provides
  several algorithms for computing partitions with respect to
  Euclidean distance.</li>
  <li>Function <code>pam()</code> from package <pkg>cluster</pkg> implements
  partitioning around medoids and can work with arbitrary
  distances. Function <code>clara()</code> is a
  wrapper to <code>pam()</code> for larger data sets. Silhouette plots
  and spanning ellipses can be used for visualization.
  </li>
  <li>Package <pkg>apcluster</pkg> implements Frey's and Dueck's
  Affinity Propagation clustering. The algorithms in the package are analogous
  to the Matlab code published by Frey and Dueck.</li>
  <li>Package <pkg>clusterSim</pkg> allows to search for the optimal
  clustering procedure for a given dataset.</li>
  <li>Package <pkg>clustMixType</pkg> implements Huangâ€™s k-prototypes
  extension of k-means for mixed type data.</li>
  <li>Package <pkg>evclust</pkg> implements various clustering
  algorithms that produce a credal partition, i.e., a set of
  Dempster-Shafer mass functions representing the membership of
  objects to clusters.</li>
  <li>Package <pkg>flexclust</pkg> provides k-centroid cluster
  algorithms for arbitrary distance measures, hard competitive
  learning, neural gas and QT clustering. Neighborhood graphs and
  image plots of partitions are available for visualization. Some of
  this functionality is also provided by package <pkg>cclust</pkg>.
  </li>
  <li>Package <pkg>kernlab</pkg> provides a weighted kernel version of
  the k-means algorithm by <code>kkmeans</code> and spectral
  clustering by <code>specc</code>.</li>
  <li>Package <pkg>kml</pkg> provides k-means
  clustering specifically for longitudinal (joint) data.</li>
  <li>Package <pkg>skmeans</pkg> allows spherical k-Means Clustering,
   i.e. k-means clustering with cosine similarity. It features several
   methods, including a genetic and a simple fixed-point algorithm and
   an interface to the CLUTO vcluster program for clustering
   high-dimensional datasets.</li>
  <li>Package <pkg>trimcluster</pkg> provides trimmed k-means
  clustering. Package <pkg>tclust</pkg> also allows for trimmed
  k-means clustering. In addition using this package other covariance
  structures can also be specified for the clusters.</li>
</ul>
<p><strong>Model-Based Clustering:</strong></p>
<ul><li>ML estimation:
<ul>
  <li>For semi- or partially supervised problems, where for a part of
  the observations labels are given with certainty or with some
  probability, package <pkg>bgmm</pkg> provides belief-based and
  soft-label mixture modeling for mixtures of Gaussians with the EM
  algorithm.</li> 
  <li><pkg>EMCluster</pkg> provides EM algorithms and several
  efficient initialization methods for model-based clustering of
  finite mixture Gaussian distribution with unstructured dispersion in
  unsupervised as well as semi-supervised learning situation.</li>
  <li>Packages <pkg>funHDDC</pkg> and <pkg>funFEM</pkg>
  implement model-based functional data
  analysis.
  The <pkg>funFEM</pkg> package implements the <pkg>funFEM</pkg>
  algorithm which allows to cluster time series or, more generally,
  functional data. It is based on a discriminative functional mixture
  model which allows the clustering of the data in a unique and
  discriminative functional subspace. This model presents the
  advantage to be parsimonious and can therefore handle long time
  series.
  The <pkg>funHDDC</pkg> package implements the funHDDC algorithm
  which allows the clustering of functional data within group-specific
  functional subspaces. The funHDDC algorithm is based on a functional
  mixture model which models and clusters the data into group-specific
  functional subspaces. The approach allows afterward meaningful
  interpretations by looking at the group-specific functional
  curves. 
  </li>
  <li>Package <pkg>GLDEX</pkg> fits mixtures of generalized lambda
  distributions and for grouped conditional data package
  <pkg>mixdist</pkg> can be used.</li>
  <li>Package <pkg>HDclassif</pkg> provides function <code>hddc</code>
  to fit Gaussian mixture model to high-dimensional data where it is
  assumed that the data lives in a lower dimension than the original
  space.</li>
  <li>Package <pkg>teigen</pkg> allows to fit multivariate
  t-distribution mixture models (with eigen-decomposed covariance
  structure) from a clustering or classification point of
  view. Package <pkg>longclust</pkg> allows to fit these models as
  well as Gaussian mixture models to longitudinal data.</li>

  <li>Package <pkg>mclust</pkg> fits mixtures of Gaussians using the EM
  algorithm. It allows fine control of volume and shape of covariance
  matrices and agglomerative hierarchical clustering based on maximum
  likelihood. It provides comprehensive strategies using hierarchical
  clustering, EM and the Bayesian Information Criterion (BIC) for
  clustering, density estimation, and discriminant analysis. Package
  <pkg>Rmixmod</pkg> provides tools for fitting mixture models of
  multivariate Gaussian or multinomial components to a given data set
  with either a clustering, a density estimation or a discriminant
  analysis point of view. Package <pkg>mclust</pkg> as well as packages
  <pkg>mixture</pkg> and <pkg>Rmixmod</pkg> provide all 14 possible
  variance-covariance structures based on the eigenvalue
  decomposition.</li>
  <li>Package <pkg>MetabolAnalyze</pkg> fits mixtures of probabilistic
  principal component analysis with the EM algorithm.</li>
  <li>For grouped conditional data package <pkg>mixdist</pkg> can be
  used.</li>
  <li>Package <pkg>MixAll</pkg> provides EM estimation of diagonal
  Gaussian, gamma, Poisson and categorical mixtures combined based on
  the conditional independence assumption using different EM variants
  and allowing for missing observations. The package accesses the
  clustering part of the Statistical ToolKit <a
  href="https://www.stkpp.org/">STK++</a>.  </li>
  <li><pkg>mixtools</pkg> provides fitting with the EM algorithm for
  parametric and non-parametric (multivariate) mixtures. Parametric
  mixtures include mixtures of multinomials, multivariate normals,
  normals with repeated measures, Poisson regressions and Gaussian
  regressions (with random effects). Non-parametric mixtures include
  the univariate semi-parametric case where symmetry is imposed for
  identifiability and multivariate non-parametric mixtures with
  conditional independent assumption. In addition fitting mixtures of
  Gaussian regressions with the Metropolis-Hastings algorithm is
  available.</li>
  <li>Fitting finite mixtures of uni- and multivariate scale mixtures
  of skew-normal distributions with the EM algorithm is provided by
  package <pkg>mixsmsn</pkg>.</li>
  <li>Package <pkg>MoEClust</pkg> fits parsimonious finite
  multivariate Gaussian mixtures of experts models via the EM
  algorithm. Covariates may influence the mixing proportions and/or
  component densities and all 14 constrained covariance
  parameterizations from package <pkg>mclust</pkg> are
  implemented.</li>
  <li>Package <pkg>movMF</pkg> fits finite mixtures of von
  Mises-Fisher distributions with the EM algorithm.</li>
  <li><pkg>mritc</pkg> provides tools for classification using normal
  mixture models and (higher resolution) hidden Markov normal mixture
  models fitted by various methods.</li>
  <li><pkg>prabclus</pkg> clusters a presence-absence matrix
  object by calculating an MDS 
  from the distances, and applying maximum likelihood Gaussian
  mixtures clustering to the MDS
  points.</li>
  <li>Package <pkg>psychomix</pkg> estimates mixtures of the
  dichotomous Rasch model (via conditional ML) and the Bradley-Terry
  model. Package <pkg>mixRasch</pkg> estimates mixture Rasch models,
  including the dichotomous Rasch model, the rating scale model, and
  the partial credit model with joint maximum likelihood estimation.
  </li>
  <li>Package <pkg>pmclust</pkg> allows to use unsupervised
  model-based clustering for high dimensional (ultra) large data. The
  package uses pbdMPI to perform a parallel version of the EM
  algorithm for mixtures of Gaussians.</li>
  <li>Package <pkg>rebmix</pkg> implements the REBMIX algorithm to fit
  mixtures of conditionally independent normal, lognormal, Weibull,
  gamma, binomial, Poisson, Dirac or von Mises component densities as
  well as mixtures of multivariate normal component densities with
  unrestricted variance-covariance matrices.</li>
</ul></li>
<li>Bayesian estimation:
<ul>
  <li>Bayesian estimation of finite mixtures of multivariate Gaussians
  is possible using package <pkg>bayesm</pkg>. The package provides
  functionality for sampling from such a mixture as well as estimating
  the model using Gibbs sampling. Additional functionality for
  analyzing the MCMC chains is available for averaging
  the moments over MCMC draws, for determining the marginal densities,
  for clustering observations and for plotting the uni- and bivariate
  marginal densities.</li>
  <li>Package <pkg>bayesmix</pkg> provides Bayesian estimation using
  JAGS.</li>
  <li>Package <pkg>bclust</pkg> allows Bayesian clustering using a
  spike-and-slab hierarchical model and is suitable for clustering
  high-dimensional data.</li>
  <li>Package <pkg>Bmix</pkg> provides Bayesian Sampling for
  stick-breaking mixtures.</li>
  <li>Package <pkg>bmixture</pkg> provides Bayesian estimation of
   finite mixtures of univariate Gamma and normal distributions.</li>
  <li>Package <pkg>dpmixsim</pkg> fits Dirichlet process mixture
  models using conjugate models with normal structure. Package
  <pkg>profdpm</pkg> determines the maximum posterior estimate for
  product partition models where the Dirichlet process mixture is a
  specific case in the class.</li>
  <li>Package <pkg>GSM</pkg> fits mixtures of gamma distributions.</li> 
  <li>Package <pkg>IMIFA</pkg> fits Infinite Mixtures of Infinite
  Factor Analyzers and a flexible suite of related models for
  clustering high-dimensional data. The number of clusters
  and/or number of cluster-specific latent factors can be
  non-parametrically inferred, without recourse to model selection
  criteria.</li>
  <li>Package <pkg>mcclust</pkg> implements methods for processing a
  sample of (hard) clusterings, e.g. the MCMC output of a Bayesian
  clustering model. Among them are methods that find a single best
  clustering to represent the sample, which are based on the posterior
  similarity matrix or a relabeling algorithm.</li>
  <li>Package <pkg>mixAK</pkg> contains a mixture of statistical
  methods including the MCMC methods to analyze normal mixtures with
  possibly censored data.  </li>
  <li>Package <pkg>PReMiuM</pkg> is a package for profile regression,
  which is a Dirichlet process Bayesian clustering where the response
  is linked non-parametrically to the covariate profile.</li>
  <li>Package <pkg>rjags</pkg> provides an interface to the JAGS
  MCMC library which includes a module for mixture modelling.</li>
</ul></li>
<li>Other estimation methods:
<ul>
  <li>Package <pkg>AdMit</pkg> allows to fit an adaptive mixture of Student-t
  distributions to approximate a target density through its kernel
  function.</li>
  <li>Package <pkg>CEC</pkg> uses cross-entropy clustering to
  automatically remove unnecessary clusters, while at the same time
  allowing the simultaneous use of various types of Gaussian mixture
  models.</li>
  <li>Circular and orthogonal regression clustering using redescending
  M-estimators is provided by package <pkg>edci</pkg>.</li>
</ul>
</li>
</ul>
<p><strong>Other Cluster Algorithms:</strong></p>
<ul>
  <li>Package <pkg>ADPclust</pkg> allows to cluster high dimensional
  data based on a two dimensional decision plot. This density-distance
  plot plots for each data point the local density against the
  shortest distance to all observations with a higher local density
  value. The cluster centroids of this non-iterative procedure can be
  selected using an interactive or automatic selection mode.</li>
  <li>Package <pkg>amap</pkg> provides alternative implementations
  of k-means and agglomerative hierarchical clustering.</li>
  <li>Package <pkg>biclust</pkg> provides several algorithms to find
  biclusters in two-dimensional data.</li>
  <li>Package <pkg>cba</pkg> implements clustering techniques for
  business analytics like "rock" and "proximus".</li>
  <li>Package <pkg>CHsharp</pkg> clusters 3-dimensional data into
  their local modes based on a convergent form of Choi and Hall's
  (1999) data sharpening method.</li>
  <li>Package <pkg>clue</pkg> implements ensemble methods for both
  hierarchical and partitioning cluster methods.</li>
  <li>Package <pkg>CoClust</pkg> implements a cluster algorithm that
  is based on copula functions and therefore allows to group
  observations according to the multivariate dependence structure of
  the generating process without any assumptions on the margins.</li>
  <li>Fuzzy clustering and bagged clustering are available in package
  <pkg>e1071</pkg>. Further and more extensive tools for fuzzy
  clustering are available in package <pkg>fclust</pkg>.</li>
  <li>Package <pkg>compHclust</pkg> provides complimentary
  hierarchical clustering which was especially designed for microarray
  data to uncover structures present in the data that arise from
  'weak' genes.</li>
  <li>Package <pkg>dbscan</pkg> provides a fast reimplementation of
  the DBSCAN (density-based spatial clustering of applications with
  noise) algorithm using a kd-tree.</li>
  <li>Package <pkg>FactoClass</pkg> performs a combination of
  factorial methods and cluster analysis.</li>
  <li>The <bioc>hopach</bioc> algorithm is a hybrid between
  hierarchical methods and PAM and builds a tree by
  recursively  partitioning a data set.</li>
  <li>For graphs and networks model-based clustering approaches are
  implemented in <pkg>latentnet</pkg>.</li>
  <li>Package <pkg>optpart</pkg> contains a set of algorithms for
  creating partitions and coverings of objects largely based on
  operations on similarity relations (or matrices).</li>
  <li>Package <pkg>pdfCluster</pkg> provides tools to perform cluster
  analysis via kernel density estimation. Clusters are associated to
  the maximally connected components with estimated density above a
  threshold. In addition a tree structure associated with the
  connected components is obtained.</li>
  <li>Package <pkg>prcr</pkg> implements the 2-step cluster analysis
  where first hierarchical clustering is performed to determine the
  initial partition for the subsequent k-means clustering
  procedure.</li>
  <li>Package <pkg>randomLCA</pkg> provides the fitting of latent
  class models which optionally also include a random effect.  Package
  <pkg>poLCA</pkg> allows for polytomous variable latent class
  analysis and regression. <pkg>BayesLCA</pkg> allows to fit Bayesian
  LCA models employing the EM algorithm, Gibbs sampling or variational
  Bayes methods.</li>
  <li>Package <pkg>RPMM</pkg> fits recursively partitioned mixture
  models for Beta and Gaussian Mixtures. This is a model-based
  clustering algorithm that returns a hierarchy of classes, similar to
  hierarchical clustering, but also similar to finite mixture
  models.</li>
  <li>Self-organizing maps are available in package
  <pkg>som</pkg>.</li>
  <li>Several packages provide cluster algorithms which have been
  developed for bioinformatics applications. These packages include
  <pkg>FunCluster</pkg> for profiling microarray expression data
  and <pkg>ORIClust</pkg>
  for order-restricted information-based clustering.</li>
</ul>
  
<p><strong>Cluster-wise Regression:</strong></p>
<ul>
  <li>Multigroup mixtures of latent Markov models on mixed categorical
  and continuous data (including time series) can be fitted using
  <pkg>depmix</pkg> or <pkg>depmixS4</pkg>. The parameters are
  optimized using a general purpose optimization routine given linear
  and nonlinear constraints on the parameters.</li>
  <li>Package <pkg>flexCWM</pkg> allows for maximum likelihood fitting of
  cluster-weighted models, a class of mixtures of regression models
  with random covariates.</li>
  <li>Package <pkg>flexmix</pkg> implements an user-extensible
  framework for EM-estimation of mixtures of regression models,
  including mixtures of (generalized) linear models.</li>
  <li>Package <pkg>fpc</pkg> provides fixed-point methods both for
  model-based clustering and linear regression. A collection of
  asymmetric projection methods can be used to plot various
  aspects of a clustering.</li>
  <li>Package <pkg>lcmm</pkg> fits a latent class linear mixed model
  which is also known as growth mixture model or heterogeneous linear
  mixed model using a maximum likelihood method.</li>
  <li>Package <pkg>mixreg</pkg> fits mixtures of one-variable
  regressions and provides the bootstrap test for the number of
  components.
  </li>
  <li><pkg>mixPHM</pkg> fits mixtures of proportional hazard models
  with the EM algorithm.</li> <li>Package <pkg>gamlss.mx</pkg> fits
  finite mixtures of gamlss family distributions.</li> </ul>

<p><strong>Additional Functionality:</strong></p>
<ul>
  <li>Mixtures of univariate normal distributions can be printed
  and plotted using package <pkg>nor1mix</pkg>.</li>
  <li>Package <pkg>clusterfly</pkg> allows
  to visualize the results of clustering algorithms.</li>
  <li>Package <pkg>clusterGeneration</pkg> contains functions for
  generating random clusters and random covariance/correlation
  matrices, calculating a separation index (data and population
  version) for pairs of clusters or cluster distributions, and 1-D and
  2-D projection plots to visualize clusters.
  Alternatively <pkg>MixSim</pkg> generates a finite mixture model
  with Gaussian components for prespecified levels of maximum and/or
  average overlaps. This model can be used to simulate data for
  studying the performance of cluster algorithms.</li>
  <li>For cluster validation package <pkg>clusterRepro</pkg> tests the
  reproducibility of a cluster. Package <pkg>clv</pkg> contains
  popular internal and external cluster validation methods ready to
  use for most of the outputs produced by functions from package
  <pkg>cluster</pkg> and <pkg>clValid</pkg> calculates several
  stability measures.</li>
  <li>Package <pkg>clustvarsel</pkg> provides variable selection for
  Gaussian model-based clustering.  Variable selection for latent
  class analysis for clustering multivariate categorical data is
  implemented in package <pkg>LCAvarsel</pkg>.
  Package <pkg>VarSelLCM</pkg> provides variable selection for
  model-based clustering of continuous, count, categorical or
  mixed-type data with missing values where the models used impose a
  conditional independence assumption given group membership.</li>
  <li>Functionality to compare the similarity between two cluster
  solutions is provided by <code>cluster.stats()</code> in package
  <pkg>fpc</pkg>.</li>
  <li>The stability of k-centroid clustering solutions fitted using
  functions from package <pkg>flexclust</pkg> can also be validated
  via <code>bootFlexclust()</code> using bootstrap methods.</li>
  <li>Package <pkg>MOCCA</pkg> provides methods to analyze cluster
  alternatives based on multi-objective optimization of cluster
  validation indices.</li>
  <li>Package <pkg>NbClust</pkg> implements 30 different indices which
  evaluate the cluster structure and should help to determine on a
  suitable number of clusters.</li>
  <li>Package <pkg>seriation</pkg> provides <code>dissplot()</code> for
  visualizing dissimilarity matrices using seriation and matrix shading. 
  This also allows to inspect cluster quality by restricting objects 
  belonging to the same cluster to be displayed in consecutive order.</li>
  <li>Package <pkg>sigclust</pkg> provides a statistical method for
  testing the significance of clustering results.</li>
  <li>Package <pkg>treeClust</pkg> calculates dissimilarities
  between data points based on their leaf memberships in regression or
  classification trees for each variable. It also performs the cluster
  analysis using the resulting dissimilarity matrix with available
  heuristic clustering algorithms in R.</li>
</ul>
  </info>

<packagelist>
<pkg>AdMit</pkg>
<pkg>ADPclust</pkg>
<pkg>amap</pkg>
<pkg>apcluster</pkg>
<pkg>BayesLCA</pkg>
<pkg>bayesm</pkg>
<pkg>bayesmix</pkg>
<pkg>bgmm</pkg>
<pkg>bclust</pkg>
<pkg>biclust</pkg>
<pkg>Bmix</pkg>
<pkg>bmixture</pkg>
<pkg>cba</pkg>
<pkg>cclust</pkg>
<pkg>CEC</pkg>
<pkg>CHsharp</pkg>
<pkg>clue</pkg>
<pkg priority="core">cluster</pkg>
<pkg>clusterfly</pkg>
<pkg>clusterGeneration</pkg>
<pkg>clusterRepro</pkg>
<pkg>clusterSim</pkg>
<pkg>clustMixType</pkg>
<pkg>clustvarsel</pkg>
<pkg>clv</pkg>
<pkg>clValid</pkg>
<pkg>CoClust</pkg>
<pkg>compHclust</pkg>
<pkg>dbscan</pkg>
<pkg>dendextend</pkg>
<pkg>depmix</pkg>
<pkg>depmixS4</pkg>
<pkg>dpmixsim</pkg>
<pkg>dynamicTreeCut</pkg>
<pkg>e1071</pkg>
<pkg>edci</pkg>
<pkg>EMCluster</pkg>
<pkg>evclust</pkg>
<pkg>FactoClass</pkg>
<pkg>fastcluster</pkg>
<pkg>fclust</pkg>
<pkg>flashClust</pkg>
<pkg priority="core">flexclust</pkg>
<pkg>flexCWM</pkg>
<pkg priority="core">flexmix</pkg>
<pkg>fpc</pkg>
<pkg>FunCluster</pkg>
<pkg>funFEM</pkg>
<pkg>funHDDC</pkg>
<pkg>gamlss.mx</pkg>
<pkg>genie</pkg>
<pkg>GLDEX</pkg>
<pkg>GSM</pkg>
<pkg>HDclassif</pkg>
<pkg>hybridHclust</pkg>
<pkg>idendr0</pkg>
<pkg>IMIFA</pkg>
<pkg>isopam</pkg>
<pkg>kernlab</pkg>
<pkg>kml</pkg>
<pkg>latentnet</pkg>
<pkg>LCAvarsel</pkg>
<pkg>lcmm</pkg>
<pkg>longclust</pkg>
<pkg>mcclust</pkg>
<pkg priority="core">mclust</pkg>
<pkg>MetabolAnalyze</pkg>
<pkg>mixsmsn</pkg>
<pkg>mixAK</pkg>
<pkg>MixAll</pkg>
<pkg>mixdist</pkg>
<pkg>mixPHM</pkg>
<pkg>mixRasch</pkg>
<pkg>mixreg</pkg>
<pkg>MixSim</pkg>
<pkg>mixtools</pkg>
<pkg>mixture</pkg>
<pkg>MOCCA</pkg>
<pkg>MoEClust</pkg>
<pkg>movMF</pkg>
<pkg>mritc</pkg>
<pkg>NbClust</pkg>
<pkg>nor1mix</pkg>
<pkg>optpart</pkg>
<pkg>ORIClust</pkg>
<pkg>pdfCluster</pkg>
<pkg>pmclust</pkg>
<pkg>poLCA</pkg>
<pkg>prabclus</pkg>
<pkg>prcr</pkg>
<pkg>PReMiuM</pkg>
<pkg>profdpm</pkg>
<pkg>protoclust</pkg>
<pkg>psychomix</pkg>
<pkg>pvclust</pkg>
<pkg>randomLCA</pkg>
<pkg>rebmix</pkg>
<pkg>rjags</pkg>
<pkg priority="core">Rmixmod</pkg>
<pkg>RPMM</pkg>
<pkg>seriation</pkg>
<pkg>sigclust</pkg>
<pkg>skmeans</pkg>
<pkg>som</pkg>
<pkg>tclust</pkg>
<pkg>teigen</pkg>
<pkg>treeClust</pkg>
<pkg>trimcluster</pkg>
<pkg>VarSelLCM</pkg>
</packagelist>

<links>
<view>MachineLearning</view>
<bioc>hopach</bioc>
</links>

</CRANTaskView>
